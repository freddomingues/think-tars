# üöÄ Sistema de Assistente Jur√≠dico Inteligente com IA

> **Nota:** Este projeto **n√£o utiliza mais AWS** (S3, DynamoDB). A base de conhecimento vem dos **arquivos que os clientes fazem upload na aplica√ß√£o** (demos) e do **Pinecone**. Threads e conversas s√£o armazenados **em mem√≥ria**.

## üìã Sum√°rio

1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura do Sistema](#arquitetura-do-sistema)
3. [Subprojetos](#subprojetos)
   - [3.1. Agente de IA para D√∫vidas de Contratos](#31-agente-de-ia-para-d√∫vidas-de-contratos)
   - [3.2. Agente de IA para D√∫vidas e Atendimento do FAQ](#32-agente-de-ia-para-d√∫vidas-e-atendimento-do-faq)
   - [3.3. Agente de IA para An√°lise de Dados](#33-agente-de-ia-para-an√°lise-de-dados)
   - [3.4. Sistema de An√°lise de Sentimento](#34-sistema-de-an√°lise-de-sentimento)
4. [Componentes T√©cnicos](#componentes-t√©cnicos)
5. [Fluxos Operacionais](#fluxos-operacionais)
6. [Infraestrutura e Deploy](#infraestrutura-e-deploy)
7. [Configura√ß√£o](#configura√ß√£o)

---

## üéØ Vis√£o Geral

Este projeto implementa um **sistema de assistentes de IA** com m√∫ltiplos agentes. Utiliza **Large Language Models (LLMs)** da OpenAI, busca vetorial com **Pinecone**, e os **arquivos enviados pelos clientes na aplica√ß√£o** como base de conhecimento. Deploy na Render.

### Objetivos Principais

- **Assistentes conversacionais**: M√∫ltiplos agentes especializados (jur√≠dico, investimento, etc.)
- **Base de Conhecimento Privada**: Utilizar documentos internos (contratos e FAQs) como fonte de verdade
- **An√°lise Inteligente**: Prover an√°lises de dados e m√©tricas atrav√©s de linguagem natural
- **Monitoramento de Sentimento**: Analisar o estado emocional das conversas para melhorar o atendimento
- **Escalabilidade**: Arquitetura preparada para alto volume de requisi√ß√µes simult√¢neas

### Tecnologias Principais

- **LLM**: OpenAI GPT-4o (Assistant API)
- **Busca Vetorial**: Pinecone (namespaces separados para contratos e FAQs)
- **Armazenamento**: AWS S3 (documentos), AWS DynamoDB (conversas e threads)
- **Processamento**: Python 3.12, Flask, asyncio
- **Deploy**: Render (aplica√ß√£o principal)

---

## üèóÔ∏è Arquitetura do Sistema

### Diagrama de Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Render (Aplica√ß√£o Flask)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  app/main.py                                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ API de demos (/api/demos)                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Tools HTTP (search_contracts, search_faqs)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ Frontend em /demos                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  OpenAI Assistant API                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Thread Management (contexto de conversa)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ Tool Selection (decide qual tool usar)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ Response Generation                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Pinecone (Vector DB)     ‚îÇ  ‚îÇ  Upload de PDF (demos)   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ namespace: contracts ‚îÇ  ‚îÇ  Arquivos dos clientes   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ namespace: faqs      ‚îÇ  ‚îÇ  ‚Üí OpenAI File Search    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Fluxo de Dados Global

1. **Base de conhecimento**: Arquivos enviados pelos clientes na aplica√ß√£o (upload de PDF) + Pinecone
2. **Demos**: Frontend em `/demos` ‚Üí API de demos ‚Üí OpenAI Assistant ‚Üí resposta no chat
3. **Tools**: Assistant usa search_contracts e search_faqs (Pinecone) quando necess√°rio

---

## üîß Subprojetos

O sistema √© composto por **4 subprojetos principais**, cada um com responsabilidades espec√≠ficas:

---

### 3.1. Agente de IA para D√∫vidas de Contratos

#### Vis√£o Geral

Agente especializado em responder perguntas espec√≠ficas sobre **termos, cl√°usulas e detalhes de contratos jur√≠dicos**. Utiliza busca vetorial em um namespace dedicado no Pinecone que cont√©m embeddings de documentos contratuais processados.

#### Componentes Principais

**3.1.1. Pipeline de Ingest√£o de Contratos**

```12:87:ingest/ingest_contracts.py
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50

# Inicializa cliente S3
s3_client = boto3.client(
    "s3",
    aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
    aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,
    region_name=settings.AWS_REGION
)

def list_pdfs_in_bucket(prefix: str = None) -> list[str]:
    """Lista todos os PDFs do bucket com prefixo opcional."""
    # ... implementa√ß√£o ...

def index_pdf_from_s3(s3_key: str):
    """Baixa PDF do S3, extrai texto e indexa no Pinecone."""
    # ... implementa√ß√£o ...

def index_all_contracts():
    """Indexa todos os contratos da raiz do bucket S3."""
    # ... implementa√ß√£o ...
```

**Arquivos:**
- `ingest/ingest_contracts.py`: L√≥gica de ingest√£o e indexa√ß√£o
- `ingest/cache_manager.py`: Sistema de cache para evitar reprocessamento
- `data_ingestion/pdf_processor.py`: Extra√ß√£o de texto de PDFs

**Processo:**
1. Lista PDFs na raiz do bucket S3 (excluindo `faqs/`)
2. Verifica cache para identificar documentos novos/atualizados
3. Para cada PDF:
   - Baixa do S3
   - Extrai texto usando `pypdf`
   - Divide em chunks de 500 caracteres (overlap 50)
   - Gera embeddings via OpenAI (`text-embedding-ada-002`)
   - Indexa no Pinecone no namespace `contracts`

**3.1.2. Tool de Busca: `search_contracts`**

```89:93:ingest/ingest_contracts.py
def search_contracts(query: str, k: int = 5) -> str:
    """Busca trechos de contratos via Pinecone."""
    results = pinecone_client.search(query=query, k=k, namespace="contracts")
    docs = [r for r in results['documents'][0]]
    return "\n".join(docs) if docs else "Nenhum trecho relevante de contrato encontrado."
```

**Defini√ß√£o da Tool (OpenAI):**

```5:16:llm_assistant/tools.py
    {
        "type": "function",
        "function": {
            "name": "search_contracts",
            "description": "Busca trechos de contratos jur√≠dicos relevantes.",
            "parameters": {
                "type": "object",
                "properties": {"query": {"type": "string"}, "k": {"type": "integer", "default": 5}},
                "required": ["query"]
            }
        }
    }
```

**3.1.3. Endpoint REST**

```83:99:app/main.py
@app.route('/api/tools/search_contracts', methods=['POST'])
def search_contracts():
    data = request.json
    query = data.get("query")
    if not query:
        log_error('app.main', "Missing 'query' parameter")
        return jsonify({"error": "Missing 'query' parameter"}), 400

    try:
        client, namespace = get_chroma_client_contract()
        results = client.search(query=query, k=3, namespace=namespace)
        docs_found = len(results.get('documents', [[]])[0])
        log_tool_call('search_contracts', query, docs_found)
        return jsonify(results), 200
    except Exception as e:
        log_error('app.main', f"Erro na busca de contratos: {e}")
        return jsonify({"error": "Internal server error"}), 500
```

#### Fluxo Operacional

```
Usu√°rio pergunta sobre contrato
         ‚îÇ
         ‚ñº
OpenAI Assistant analisa pergunta
         ‚îÇ
         ‚ñº
Decide usar tool "search_contracts"
         ‚îÇ
         ‚ñº
Tool √© chamada com query extra√≠da
         ‚îÇ
         ‚ñº
Pinecone busca no namespace "contracts"
         ‚îÇ
         ‚ñº
Retorna top 3 chunks mais similares
         ‚îÇ
         ‚ñº
Assistant gera resposta baseada nos chunks
         ‚îÇ
         ‚ñº
Resposta exibida no chat (demos)
```

#### Instru√ß√µes do Assistente

O assistente √© configurado para usar `search_contracts` **apenas quando a pergunta for especificamente sobre contratos**:

```7:8:llm_assistant/prompt_templates.py
- Use a ferramenta 'search_contracts' apenas se a pergunta for especificamente sobre termos e detalhes de contratos.
- Use a ferramenta 'search_faqs' para responder a perguntas gerais sobre a empresa, seus servi√ßos ou outras d√∫vidas que n√£o sejam sobre contratos.
```

---

### 3.2. Agente de IA para D√∫vidas e Atendimento do FAQ

#### Vis√£o Geral

Agente focado em responder **perguntas gerais sobre a empresa, servi√ßos, procedimentos e outras d√∫vidas frequentes** que n√£o sejam relacionadas a contratos. Utiliza um namespace separado no Pinecone para FAQs.

#### Componentes Principais

**3.2.1. Pipeline de Ingest√£o de FAQs**

```22:64:ingest/ingest_faqs.py
def index_pdf_bytes(file_bytes, source_name):
    """Indexa PDF na cole√ß√£o de FAQ."""
    text = extract_text_from_pdf_bytes(file_bytes)
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,   # menor
        chunk_overlap=50  # menor overlap
    )
    chunks = splitter.split_text(text)

    # Gera embeddings em batch (muito mais eficiente)
    embeddings = pinecone_client.embedding_model.embed_documents(chunks)

    metadatas = [{"source": source_name, "chunk": i} for i in range(len(chunks))]
    ids = [f"{source_name}_{i}" for i in range(len(chunks))]

    pinecone_client.add_documents(
        documents=chunks,
        embeddings=embeddings,
        metadatas=metadatas,
        ids=ids,
        namespace="faqs"
    )
```

**Arquivos:**
- `ingest/ingest_faqs.py`: L√≥gica espec√≠fica para FAQs
- Processa PDFs da pasta `faqs/` no S3

**Diferen√ßas do Pipeline de Contratos:**
- Processa arquivos da pasta `faqs/` (prefixo configur√°vel)
- Namespace separado: `faqs`
- Mesma estrat√©gia de chunking (500 caracteres, overlap 50)

**3.2.2. Tool de Busca: `search_faqs`**

```86:90:ingest/ingest_faqs.py
def search_faqs(query: str, k: int = 5) -> str:
    """Busca trechos de FAQs via Pinecone."""
    results = pinecone_client.search(query=query, k=k, namespace="faqs")
    docs = [r for r in results['documents'][0]]
    return "\n".join(docs) if docs else "Nenhum trecho relevante de FAQ encontrado."
```

**Defini√ß√£o da Tool:**

```18:29:llm_assistant/tools.py
    {
        "type": "function",
        "function": {
            "name": "search_faqs",
            "description": "Busca trechos de FAQs relevantes.",
            "parameters": {
                "type": "object",
                "properties": {"query": {"type": "string"}, "k": {"type": "integer", "default": 5}},
                "required": ["query"]
            }
        }
    }
```

**3.2.3. Endpoint REST**

```101:117:app/main.py
@app.route('/api/tools/search_faqs', methods=['POST'])
def search_faqs():
    data = request.json
    query = data.get("query")
    if not query:
        log_error('app.main', "Missing 'query' parameter")
        return jsonify({"error": "Missing 'query' parameter"}), 400

    try:
        client, namespace = get_chroma_client_faqs()
        results = client.search(query=query, k=3, namespace=namespace)
        docs_found = len(results.get('documents', [[]])[0])
        log_tool_call('search_faqs', query, docs_found)
        return jsonify(results), 200
    except Exception as e:
        log_error('app.main', f"Erro na busca de FAQs: {e}")
        return jsonify({"error": "Internal server error"}), 500
```

#### Fluxo Operacional

Similar ao de contratos, mas:
- Usa namespace `faqs` no Pinecone
- Processa documentos da pasta `faqs/` no S3
- √â usado para perguntas gerais (n√£o sobre contratos)

#### Decis√£o Autom√°tica de Tool

O OpenAI Assistant decide automaticamente qual tool usar baseado nas instru√ß√µes:

```7:8:llm_assistant/prompt_templates.py
- Use a ferramenta 'search_contracts' apenas se a pergunta for especificamente sobre termos e detalhes de contratos.
- Use a ferramenta 'search_faqs' para responder a perguntas gerais sobre a empresa, seus servi√ßos ou outras d√∫vidas que n√£o sejam sobre contratos.
```

---

### 3.3. Agente de IA para An√°lise de Dados

#### Vis√£o Geral

Agente especializado em **consultar, analisar e gerar insights** a partir de planilhas Excel armazenadas no S3. Permite ao usu√°rio fazer perguntas em linguagem natural sobre dados, KPIs, estat√≠sticas e m√©tricas.

#### Componentes Principais

**3.3.1. Sistema de Consulta de Planilhas**

```28:75:ingest/query_spreadsheet.py
def load_spreadsheet_from_s3(file_name: str = "base_dados_mock.xlsx") -> Optional[pd.DataFrame]:
    """
    Carrega uma planilha Excel do S3.
    
    Args:
        file_name: Nome do arquivo Excel no bucket S3
        
    Returns:
        DataFrame com os dados da planilha ou None se houver erro
    """
    global _spreadsheet_cache, _cache_file_name
    
    # Verifica se j√° est√° em cache
    if _spreadsheet_cache is not None and _cache_file_name == file_name:
        logger.info(f"üìä [SPREADSHEET] Usando planilha em cache: {file_name}")
        return _spreadsheet_cache
    
    try:
        # Busca o arquivo no S3
        logger.info(f"üì• [SPREADSHEET] Carregando planilha do S3: {file_name}")
        
        response = s3_client.get_object(
            Bucket=settings.S3_BUCKET_NAME,
            Key=file_name
        )
        
        # L√™ o conte√∫do do arquivo
        file_bytes = response['Body'].read()
        
        # Carrega o Excel usando pandas
        excel_file = io.BytesIO(file_bytes)
        df = pd.read_excel(excel_file, engine='openpyxl')
        
        # Atualiza cache
        _spreadsheet_cache = df
        _cache_file_name = file_name
        
        logger.info(f"‚úÖ [SPREADSHEET] Planilha carregada com sucesso: {len(df)} linhas, {len(df.columns)} colunas")
        logger.info(f"üìã [SPREADSHEET] Colunas: {', '.join(df.columns.tolist())}")
        
        return df
```

**Funcionalidades:**
- Cache em mem√≥ria para evitar recarregar a planilha a cada consulta
- Suporte a m√∫ltiplas abas
- Tratamento de erros robusto

**3.3.2. Tipos de Consultas Suportadas**

O sistema suporta m√∫ltiplos tipos de an√°lise via linguagem natural:

**a) Informa√ß√µes da Estrutura:**
```151:162:ingest/query_spreadsheet.py
        if "informa√ß√µes" in query_lower or "info" in query_lower or "estrutura" in query_lower:
            return {
                "success": True,
                "type": "info",
                "data": {
                    "rows": len(df),
                    "columns": len(df.columns),
                    "column_names": df.columns.tolist(),
                    "data_types": df.dtypes.astype(str).to_dict()
                },
                "message": f"Planilha possui {len(df)} linhas e {len(df.columns)} colunas"
            }
```

**b) Estat√≠sticas Descritivas:**
```164:181:ingest/query_spreadsheet.py
        elif "estat√≠stica" in query_lower or "resumo" in query_lower or "describe" in query_lower:
            numeric_cols = df.select_dtypes(include=['number']).columns
            if len(numeric_cols) > 0:
                stats = df[numeric_cols].describe()
                return {
                    "success": True,
                    "type": "statistics",
                    "data": stats.to_dict(),
                    "message": "Estat√≠sticas descritivas das colunas num√©ricas"
                }
```

**c) Valores √önicos:**
```183:212:ingest/query_spreadsheet.py
        elif "valores √∫nicos" in query_lower or "unique" in query_lower or "distintos" in query_lower:
            # Tenta identificar a coluna mencionada na query
            cols = [col for col in df.columns if col.lower() in query_lower]
            if cols:
                col = cols[0]
                unique_values = df[col].unique().tolist()
                return {
                    "success": True,
                    "type": "unique_values",
                    "column": col,
                    "data": unique_values,
                    "count": len(unique_values),
                    "message": f"Valores √∫nicos da coluna '{col}': {len(unique_values)} valores"
                }
```

**d) C√°lculos (M√©dia, Soma, M√°ximo, M√≠nimo):**
```237:300:ingest/query_spreadsheet.py
        elif any(word in query_lower for word in ["m√©dia", "m√©dio", "average", "mean"]):
            numeric_cols = df.select_dtypes(include=['number']).columns
            if len(numeric_cols) > 0:
                means = df[numeric_cols].mean().to_dict()
                return {
                    "success": True,
                    "type": "mean",
                    "data": means,
                    "message": "M√©dias das colunas num√©ricas"
                }
        # ... similar para soma, m√°ximo, m√≠nimo ...
```

**e) An√°lise de KPIs:**
```315:337:ingest/query_spreadsheet.py
        elif "kpi" in query_lower or "indicador" in query_lower:
            numeric_cols = df.select_dtypes(include=['number']).columns
            result = {
                "kpis": {}
            }
            
            for col in numeric_cols:
                result["kpis"][col] = {
                    "mean": float(df[col].mean()),
                    "median": float(df[col].median()),
                    "sum": float(df[col].sum()),
                    "min": float(df[col].min()),
                    "max": float(df[col].max()),
                    "std": float(df[col].std())
                }
            
            return {
                "success": True,
                "type": "kpis",
                "data": result,
                "message": "An√°lise de KPIs das colunas num√©ricas"
            }
```

**3.3.3. Tool de Consulta: `query_spreadsheet`**

```30:63:llm_assistant/tools.py
    {
        "type": "function",
        "function": {
            "name": "query_spreadsheet",
            "description": """Realiza consultas e an√°lises de dados em planilhas Excel do S3.
            Use esta ferramenta para:
            - Obter informa√ß√µes sobre a estrutura da planilha (colunas, linhas, tipos de dados)
            - Calcular estat√≠sticas descritivas (m√©dia, mediana, soma, m√°ximo, m√≠nimo)
            - Analisar KPIs e indicadores
            - Contar valores √∫nicos ou totais
            - Filtrar e visualizar dados
            - Realizar an√°lises de dados e m√©tricas
            
            A planilha padr√£o √© 'base_dados_mock.xlsx' que est√° no mesmo bucket S3 dos outros arquivos.
            Esta ferramenta √© √∫til para responder perguntas sobre dados, m√©tricas, KPIs e an√°lises.""",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": """Descri√ß√£o da consulta ou an√°lise desejada. 
                        Exemplos: 
                        - 'mostrar informa√ß√µes da planilha'
                        - 'calcular m√©dia da coluna vendas'
                        - 'contar valores √∫nicos de produtos'
                        - 'analisar KPIs de performance'
                        - 'estat√≠sticas descritivas'
                        - 'filtrar dados onde status √© ativo'"""
                    }
                },
                "required": ["query"]
            }
        }
    }
```

**3.3.4. Endpoint REST**

```119:135:app/main.py
@app.route('/api/tools/query_spreadsheet', methods=['POST'])
def query_spreadsheet():
    """Endpoint para consultas em planilhas Excel do S3."""
    data = request.json
    query = data.get("query")
    if not query:
        log_error('app.main', "Missing 'query' parameter")
        return jsonify({"error": "Missing 'query' parameter"}), 400

    try:
        from ingest.query_spreadsheet import query_spreadsheet_data
        result = query_spreadsheet_data(query)
        log_tool_call('query_spreadsheet', query, len(result) if result else 0)
        return jsonify({"result": result}), 200
    except Exception as e:
        log_error('app.main', f"Erro na consulta de planilha: {e}")
        return jsonify({"error": f"Internal server error: {str(e)}"}), 500
```

#### Fluxo Operacional

```
Usu√°rio pergunta sobre dados/KPIs
         ‚îÇ
         ‚ñº
OpenAI Assistant identifica necessidade de an√°lise
         ‚îÇ
         ‚ñº
Decide usar tool "query_spreadsheet"
         ‚îÇ
         ‚ñº
Tool extrai inten√ß√£o da query (m√©dia, soma, etc)
         ‚îÇ
         ‚ñº
Sistema carrega planilha do S3 (com cache)
         ‚îÇ
         ‚ñº
Executa an√°lise apropriada (pandas)
         ‚îÇ
         ‚ñº
Formata resultados em texto leg√≠vel
         ‚îÇ
         ‚ñº
Assistant gera resposta explicativa
         ‚îÇ
         ‚ñº
Resposta enviada ao usu√°rio
```

#### Exemplos de Queries Suportadas

- "Mostrar informa√ß√µes da planilha"
- "Calcular m√©dia da coluna vendas"
- "Estat√≠sticas descritivas"
- "Analisar KPIs de performance"
- "Contar valores √∫nicos de produtos"
- "Qual o total de vendas?"
- "Mostrar os 10 maiores valores"

---

### 3.4. Sistema de An√°lise de Sentimento

#### Vis√£o Geral

Sistema avan√ßado que **analisa o sentimento das mensagens dos usu√°rios** em tempo real, permitindo que o assistente adapte seu tom e estrat√©gia de resposta. Os resultados s√£o persistidos no DynamoDB e visualizados no dashboard.

#### Componentes Principais

**3.4.1. Analisador Avan√ßado de Sentimento**

```17:95:sentiment_analyses/advanced_sentiment.py
class AdvancedSentimentAnalyzer:
    def __init__(self):
        self.vader_analyzer = SentimentIntensityAnalyzer()
        
        # Palavras-chave para contexto espec√≠fico
        self.positive_keywords = [
            'obrigado', 'obrigada', 'perfeito', 'excelente', '√≥timo', 'bom', 'legal',
            'gostei', 'interessante', 'sim', 'claro', 'entendi', 'beleza', 'show',
            'maravilhoso', 'fant√°stico', 'incr√≠vel', 'top', 'demais', 'massa'
        ]
        
        self.negative_keywords = [
            'n√£o', 'nunca', 'jamais', 'ruim', 'p√©ssimo', 'terr√≠vel', 'horr√≠vel',
            'problema', 'erro', 'falha', 'defeito', 'reclama√ß√£o', 'insatisfeito',
            'frustrado', 'irritado', 'chateado', 'bravo', 'raiva', '√≥dio'
        ]
        
        self.urgency_keywords = [
            'urgente', 'r√°pido', 'agora', 'imediato', 'emerg√™ncia', 'pressa',
            'depressa', 'logo', 'j√°', 'hoje', 'amanh√£', 'asap'
        ]

    def analyze_sentiment(self, text: str) -> Dict:
        """
        Analisa o sentimento de um texto usando m√∫ltiplos m√©todos.
        """
        # ... implementa√ß√£o ...
```

**M√©todos de An√°lise:**

1. **VADER Sentiment Analyzer**: An√°lise l√©xica e regras espec√≠ficas para portugu√™s/ingl√™s
2. **TextBlob**: An√°lise baseada em polaridade e subjetividade
3. **An√°lise de Palavras-Chave**: Dicion√°rio customizado com palavras positivas/negativas/urg√™ncia
4. **Score Combinado**: Combina√ß√£o ponderada dos m√©todos acima

**C√°lculo de Score Combinado:**

```135:161:sentiment_analyses/advanced_sentiment.py
    def _calculate_combined_score(self, vader_scores: Dict, textblob_polarity: float, 
                                keyword_analysis: Dict, urgency_score: float) -> float:
        """Calcula score combinado de todos os m√©todos."""
        # Peso para cada m√©todo
        vader_weight = 0.4
        textblob_weight = 0.3
        keyword_weight = 0.2
        urgency_weight = 0.1
        
        # Score do VADER (compound score)
        vader_score = vader_scores['compound']
        
        # Score do TextBlob
        textblob_score = textblob_polarity
        
        # Score das palavras-chave
        keyword_score = keyword_analysis['score']
        
        # Combina os scores
        combined = (
            vader_score * vader_weight +
            textblob_score * textblob_weight +
            keyword_score * keyword_weight +
            urgency_score * urgency_weight
        )
        
        return combined
```

**3.4.2. Integra√ß√£o no Fluxo de Mensagens**

```156:179:app/main.py
            # An√°lise de sentimento da mensagem
            logger.info(f"üé≠ [SENTIMENT] Analisando sentimento da mensagem...")
            sentiment_analysis = sentiment_analyzer.analyze_sentiment(message_content)
            logger.info(f"üé≠ [SENTIMENT] {phone_number} - Sentimento: {sentiment_analysis['sentiment']} (Confian√ßa: {sentiment_analysis['confidence']:.2f})")
            
            # Salva mensagem e an√°lise no banco
            logger.info(f"üíæ [DATABASE] Salvando mensagem no banco...")
            message_id = conversation_manager.save_message(
                conversation_id=thread_id,
                phone_number=phone_number,
                message=message_content,
                sender='user'
            )
            
            if message_id:
                logger.info(f"‚úÖ [DATABASE] Mensagem salva com ID: {message_id}")
                conversation_manager.save_sentiment_analysis(
                    message_id=message_id,
                    conversation_id=thread_id,
                    sentiment_data=sentiment_analysis
                )
                logger.info(f"‚úÖ [DATABASE] An√°lise de sentimento salva")
```

**3.4.3. Adapta√ß√£o de Resposta Baseada em Sentimento**

O assistente adapta seu tom baseado no sentimento detectado:

```18:23:llm_assistant/prompt_templates.py
# An√°lise de Sentimento
- Considere o sentimento do usu√°rio ao responder
- Se o sentimento for NEGATIVO: seja mais emp√°tico, ofere√ßa ajuda e solu√ß√µes
- Se o sentimento for POSITIVO: mantenha o tom positivo e proativo
- Se o sentimento for NEUTRO: seja profissional e direto
- Adapte seu tom de acordo com a urg√™ncia detectada na mensagem
```

**3.4.4. Envio de Metadata com Sentimento**

```275:277:app/main.py
                    # Resposta retornada ao cliente (demos) ou exibida no chat
```

**3.4.5. An√°lise de Sentimento de Conversa Completa**

```185:241:sentiment_analyses/advanced_sentiment.py
    def analyze_conversation_sentiment(self, messages: List[Dict]) -> Dict:
        """Analisa o sentimento geral de uma conversa."""
        if not messages:
            return {'overall_sentiment': 'neutro', 'confidence': 0.0, 'trend': 'est√°vel'}
        
        sentiments = []
        confidences = []
        
        for message in messages:
            if message.get('sender') == 'user':  # Apenas mensagens do usu√°rio
                analysis = self.analyze_sentiment(message.get('message', ''))
                sentiments.append(analysis['sentiment'])
                confidences.append(analysis['confidence'])
        
        # ... determina sentimento geral e tend√™ncia ...
        
        return {
            'overall_sentiment': overall_sentiment,
            'confidence': avg_confidence,
            'trend': trend,
            'sentiment_distribution': {
                'positivo': positive_count,
                'negativo': negative_count,
                'neutro': neutral_count
            },
            'total_messages': total
        }
```

**Funcionalidades:**
- Calcula sentimento geral da conversa
- Identifica tend√™ncia (melhorando, piorando, est√°vel)
- Distribui√ß√£o de sentimentos
- Confian√ßa m√©dia

#### Estrutura de Dados Retornada

```python
{
    'sentiment': 'positivo' | 'negativo' | 'neutro',
    'confidence': 0.0-1.0,
    'scores': {
        'vader': {...},
        'textblob_polarity': float,
        'textblob_subjectivity': float,
        'keyword_analysis': {...},
        'urgency_score': float,
        'combined_score': float
    },
    'timestamp': 'ISO8601',
    'text_length': int,
    'word_count': int
}
```

#### Persist√™ncia no DynamoDB

```191:216:data_store/conversation_schema.py
    def save_sentiment_analysis(self, message_id: str, conversation_id: str, 
                               sentiment_data: Dict) -> str:
        """Salva an√°lise de sentimento de uma mensagem."""
        analysis_id = f"sentiment_{message_id}"
        
        try:
            # Converte floats para Decimal
            converted_data = self._convert_floats_to_decimal(sentiment_data)
            
            self.sentiment_table.put_item(
                Item={
                    'analysis_id': analysis_id,
                    'message_id': message_id,
                    'conversation_id': conversation_id,
                    'sentiment': converted_data.get('sentiment'),
                    'confidence': converted_data.get('confidence', Decimal('0.0')),
                    'scores': json.dumps(converted_data.get('scores', {}), cls=DecimalEncoder),
                    'timestamp': datetime.now().isoformat()
                }
            )
            
            return analysis_id
```

---

## üîß Componentes T√©cnicos

### 4.1. Gerenciamento de Assistente OpenAI

**Arquivo:** `llm_assistant/assistant_manager.py`

**Fun√ß√µes Principais:**

```9:34:llm_assistant/assistant_manager.py
def create_or_get_assistant(assistant_name: str = "Assistente Jur√≠dico de Contratos") -> str:
    """
    Cria um novo assistente ou recupera um existente com base no nome.
    Retorna o ID do assistente.
    """
    try:
        # Tenta listar assistentes e encontrar um com o nome
        my_assistants = openai_client.beta.assistants.list(order="desc", limit="100")
        for existing_assistant in my_assistants.data:
            if existing_assistant.name == assistant_name:
                #print(f"Assistente '{assistant_name}' j√° existe! ID: {existing_assistant.id}")
                return existing_assistant.id

        # Se n√£o encontrou, cria um novo
        assistant = openai_client.beta.assistants.create(
            name=assistant_name,
            instructions=DEFAULT_ASSISTANT_INSTRUCTIONS,
            model=LLM_MODEL,
            tools=TOOLS_DEFINITION
        )
        #print(f"Assistente '{assistant_name}' criado com sucesso! ID: {assistant.id}")
        return assistant.id

    except Exception as e:
        #print(f"Erro ao criar/obter o Assistente: {e}")
        return None
```

**Inicializa√ß√£o na Aplica√ß√£o:**

```57:72:app/main.py
def initialize_application():
    """Inicializa o assistente LLM."""
    global ASSISTANT_ID
    logger.info("üöÄ Inicializando aplica√ß√£o...")
    try:
        assistant_id_local = create_or_get_assistant("Assistente Jur√≠dico de Contratos")
        if not assistant_id_local:
            raise ValueError("Falha cr√≠tica: n√£o foi poss√≠vel criar/obter Assistant ID.")
        ASSISTANT_ID = assistant_id_local
        logger.info(f"‚úÖ Assistant ID obtido: {ASSISTANT_ID}")
        logger.info("‚úÖ Aplica√ß√£o inicializada com sucesso!")
    except (APIError, AuthenticationError, RateLimitError, APIConnectionError, ValueError, Exception) as e:
        logger.error(f"‚ùå ERRO na inicializa√ß√£o: {type(e).__name__}: {e}")
        sys.exit(1)

initialize_application()
```

### 4.2. Sistema de Busca Vetorial (Pinecone)

**Arquivo:** `llm_assistant/pinecone_client.py`

**Classe Principal:**

```13:33:llm_assistant/pinecone_client.py
class PineconeClient:
    def __init__(self):
        """Inicializa o cliente Pinecone."""
        if not PINECONE_API_KEY:
            raise ValueError("PINECONE_API_KEY n√£o definida no ambiente ou no arquivo .env")
        
        # Inicializa Pinecone com a nova API
        self.pc = Pinecone(api_key=PINECONE_API_KEY)
        
        # Conecta ao √≠ndice
        self.index = self.pc.Index(PINECONE_INDEX_NAME)
        
        # Embeddings OpenAI
        embedding_model = EMBEDDING_MODEL or "text-embedding-ada-002"
        self.embedding_model = OpenAIEmbeddings(
            model=embedding_model,
            openai_api_key=OPENAI_API_KEY
        )
        
        logger.info(f"‚úÖ Pinecone conectado ao √≠ndice: {PINECONE_INDEX_NAME}")
```

**Opera√ß√µes:**
- `add_documents()`: Indexa documentos com embeddings
- `search()`: Busca por similaridade vetorial
- `delete_by_ids()`: Remove documentos espec√≠ficos
- `get_stats()`: Estat√≠sticas do √≠ndice

**Namespaces:**
- `contracts`: Para documentos contratuais
- `faqs`: Para documentos de FAQ

### 4.3. Gerenciamento de Contexto (DynamoDB)

**Arquivos:**
- `data_store/dynamodb_handler.py`: Gerenciamento de threads
- `data_store/conversation_schema.py`: Schema completo de conversas

**Persist√™ncia de Threads:**

```13:33:data_store/dynamodb_handler.py
def get_user_thread_id(phone_number: str) -> str | None:
    """
    Recupera o thread_id do usu√°rio do DynamoDB.
    Retorna o thread_id se encontrado, None caso contr√°rio ou em caso de erro.
    """
    try:
        response = table.get_item(Key={'phone_number': phone_number})
        item = response.get('Item')
        if item:
            logger.info(f"üíæ [DYNAMODB] Thread ID encontrado para {phone_number}: {item['thread_id']}")
            return item['thread_id']
        logger.info(f"üíæ [DYNAMODB] Nenhuma Thread ID encontrada para {phone_number}.")
        return None
    except ClientError as e:
        # Erros espec√≠ficos do cliente Boto3, como permiss√£o negada, etc.
        logger.error(f"‚ùå [DYNAMODB] Erro ao buscar thread ID no DynamoDB para {phone_number}: {e.response['Error']['Message']}")
        return None
```

**Schema de Conversas:**

Tabelas DynamoDB:
1. **Conversations**: Metadados de conversas
2. **Messages**: Mensagens individuais (user/assistant)
3. **SentimentAnalysis**: An√°lises de sentimento por mensagem

**√çndices:**
- `phone-number-index`: Buscar conversas por telefone
- `conversation-index`: Buscar mensagens por conversa
- `message-index`: Buscar an√°lise por mensagem

### 4.4. Processamento Ass√≠ncrono

**Arquitetura:**
- **Queue**: `queue.Queue` com capacidade de 100 mensagens
- **Worker Thread**: Processa mensagens em background
- **Thread Pool**: `ThreadPoolExecutor` com 4 workers
- **Async Processing**: Fun√ß√£o `process_message_async` usando `asyncio`

```53:55:app/main.py
# === Fila e pool de threads ===
message_queue = queue.Queue(maxsize=100)
executor = ThreadPoolExecutor(max_workers=4)
```

**Worker Background:**

```288:303:app/main.py
def background_worker():
    """Worker que consome mensagens da fila e processa."""
    logger.info("üîÑ [WORKER] Worker iniciado")
    while True:
        try:
            logger.info("‚è≥ [WORKER] Aguardando mensagem na fila...")
            phone_number, message_content = message_queue.get()
            logger.info(f"üì• [WORKER] Processando mensagem de {phone_number}")
            asyncio.run(process_message_async(phone_number, message_content))
            logger.info(f"‚úÖ [WORKER] Mensagem processada com sucesso")
        except Exception as e:
            logger.error(f"‚ùå [WORKER] Erro ao processar mensagem: {e}")
            import traceback
            traceback.print_exc()
        finally:
            message_queue.task_done()
```

**Lock por Usu√°rio:**

```142:144:app/main.py
    if phone_number not in user_locks:
        user_locks[phone_number] = asyncio.Lock()

    async with user_locks[phone_number]:
```

Garante que mensagens do mesmo usu√°rio sejam processadas sequencialmente.

### 4.5. Sistema de Cache de Documentos

**Arquivo:** `ingest/cache_manager.py`

**Funcionalidades:**
- Evita reprocessar documentos j√° indexados
- Usa hash MD5 baseado em ETag + LastModified do S3
- Persist√™ncia em JSON local

```56:79:ingest/cache_manager.py
    def is_processed(self, s3_key: str) -> bool:
        """Verifica se documento j√° foi processado."""
        current_hash = self._get_file_hash(settings.S3_BUCKET_NAME, s3_key)
        if not current_hash:
            return False
        
        cached_hash = self.cache_data["processed_docs"].get(s3_key)
        return cached_hash == current_hash
    
    def mark_processed(self, s3_key: str):
        """Marca documento como processado."""
        current_hash = self._get_file_hash(settings.S3_BUCKET_NAME, s3_key)
        if current_hash:
            self.cache_data["processed_docs"][s3_key] = current_hash
            self.cache_data["last_update"] = datetime.now().isoformat()
            self._save_cache()
    
    def get_unprocessed_docs(self, doc_keys: list) -> list:
        """Retorna lista de documentos n√£o processados."""
        unprocessed = []
        for key in doc_keys:
            if not self.is_processed(key):
                unprocessed.append(key)
        return unprocessed
```

---

## üîÑ Fluxos Operacionais

### 5.1. Fluxo de Demos (conversa no chat)

```
1. Usu√°rio acessa /demos e seleciona assistente (opcional: upload de PDF)
         ‚îÇ
         ‚ñº
2. Frontend chama API de demos (conversations, messages)
         ‚îÇ
         ‚ñº
3. Backend adiciona mensagem √† thread OpenAI e cria Run do Assistant
         ‚îÇ
         ‚ñº
4. Assistant processa e pode solicitar tools
         ‚îÇ
         ‚îú‚îÄ‚ñ∫ search_contracts ‚Üí Pinecone (namespace: contracts)
         ‚îú‚îÄ‚ñ∫ search_faqs ‚Üí Pinecone (namespace: faqs)
         ‚îî‚îÄ‚ñ∫ (outras tools: trading, etc.)
         ‚îÇ
         ‚ñº
5. Assistant gera resposta; frontend exibe no chat
```

### 5.2. Base de Conhecimento

- **Upload de PDF (demos):** Arquivo enviado pelo cliente √© processado e indexado em um vector store da OpenAI (File Search) para aquela conversa.
- **Pinecone:** Namespaces `contracts` e `faqs` podem ser alimentados por outros fluxos; as tools `search_contracts` e `search_faqs` consultam o Pinecone.

### 5.3. Fluxo de Tool Call

```
1. Assistant identifica necessidade de informa√ß√£o externa
         ‚îÇ
         ‚ñº
2. Status do Run muda para "requires_action"
         ‚îÇ
         ‚ñº
3. main.py detecta tool calls no run.required_action
         ‚îÇ
         ‚ñº
4. Para cada tool_call:
   ‚îú‚îÄ‚ñ∫ Extrai function_name e arguments
   ‚îú‚îÄ‚ñ∫ Busca fun√ß√£o em AVAILABLE_FUNCTIONS
   ‚îú‚îÄ‚ñ∫ Executa fun√ß√£o com argumentos
   ‚îî‚îÄ‚ñ∫ Coleta resultado
         ‚îÇ
         ‚ñº
5. Submete tool_outputs ao Assistant
         ‚îÇ
         ‚ñº
6. Assistant processa outputs e gera resposta final
```

**Exemplo de Execu√ß√£o:**

```196:248:app/main.py
                if run.status == 'requires_action':
                    # Processa tool calls
                    tool_outputs = []
                    for tool_call in run.required_action.submit_tool_outputs.tool_calls:
                        function_name = tool_call.function.name
                        function_args = json.loads(tool_call.function.arguments)
                        
                        logger.info(f"üîß [TOOL] Executando tool: {function_name} com args: {function_args}")
                        
                        # Executa a fun√ß√£o correspondente
                        if function_name in AVAILABLE_FUNCTIONS:
                            try:
                                function_to_call = AVAILABLE_FUNCTIONS[function_name]
                                
                                # Chama a fun√ß√£o com os argumentos
                                if function_name == "query_spreadsheet":
                                    result = function_to_call(function_args.get("query", ""))
                                elif function_name in ["search_contracts", "search_faqs"]:
                                    result = function_to_call(
                                        function_args.get("query", ""),
                                        function_args.get("k", 5)
                                    )
                                else:
                                    result = function_to_call(**function_args)
                                
                                tool_outputs.append({
                                    "tool_call_id": tool_call.id,
                                    "output": str(result) if not isinstance(result, str) else result
                                })
                                
                                log_tool_call(function_name, str(function_args), len(str(result)))
                                logger.info(f"‚úÖ [TOOL] Tool {function_name} executada com sucesso")
```

### 5.4. Fluxo de An√°lise de Sentimento

```
1. Mensagem recebida do usu√°rio
         ‚îÇ
         ‚ñº
2. AdvancedSentimentAnalyzer.analyze_sentiment()
         ‚îÇ
         ‚îú‚îÄ‚ñ∫ VADER analysis
         ‚îú‚îÄ‚ñ∫ TextBlob analysis
         ‚îú‚îÄ‚ñ∫ Keyword analysis
         ‚îî‚îÄ‚ñ∫ Urgency detection
         ‚îÇ
         ‚ñº
3. Combina scores com pesos
         ‚îÇ
         ‚ñº
4. Determina sentimento final (positivo/negativo/neutro)
         ‚îÇ
         ‚ñº
5. Salva an√°lise no DynamoDB (tabela SentimentAnalysis)
         ‚îÇ
         ‚ñº
6. Assistant usa sentimento para adaptar resposta
         ‚îÇ
         ‚ñº
7. Metadata de sentimento inclu√≠da na resposta enviada
```

---

## üöÄ Infraestrutura e Deploy

### 6.1. Render (Aplica√ß√£o Principal)

**Procfile:**

```
web: gunicorn --bind 0.0.0.0:$PORT app.main:app
```

**Caracter√≠sticas:**
- Aplica√ß√£o Flask com Gunicorn
- Porta din√¢mica via vari√°vel `$PORT`
- Auto-deploy via Git push

**Endpoints Expostos:**
- `GET /`: Health check
- `GET /demos`, `/demos/`: Frontend de demos
- `GET /api/demos/assistants`, `POST /api/demos/upload-pdf`, `POST /api/demos/conversations`, etc.
- `POST /api/tools/search_contracts`: Tool de busca de contratos (Pinecone)
- `POST /api/tools/search_faqs`: Tool de busca de FAQs (Pinecone)

### 6.2. AWS S3

**Estrutura de Pastas:**
```
s3://gen-ai-contratos/
‚îú‚îÄ‚îÄ contratos/
‚îÇ   ‚îú‚îÄ‚îÄ contrato1.pdf
‚îÇ   ‚îî‚îÄ‚îÄ contrato2.pdf
‚îú‚îÄ‚îÄ faqs/
‚îÇ   ‚îú‚îÄ‚îÄ faq1.pdf
‚îÇ   ‚îî‚îÄ‚îÄ faq2.pdf
‚îî‚îÄ‚îÄ base_dados_mock.xlsx
```

**Acesso:**
- Credenciais via vari√°veis de ambiente
- Regi√£o configur√°vel (padr√£o: `us-east-2`)

### 6.3. AWS DynamoDB

**Tabelas:**

1. **AssistantUserThreads** (via `dynamodb_handler.py`)
   - Key: `phone_number`
   - Atributos: `thread_id`, `last_updated`
   - Uso: Mapear telefone ‚Üí thread OpenAI

2. **Conversations** (via `conversation_schema.py`)
   - Key: `conversation_id`
   - GSI: `phone-number-index`
   - Atributos: `phone_number`, `last_message`, `created_at`, `message_count`

3. **Messages**
   - Key: `message_id`
   - GSI: `conversation-index`
   - Atributos: `conversation_id`, `phone_number`, `message`, `sender`, `timestamp`

4. **SentimentAnalysis**
   - Key: `analysis_id`
   - GSI: `message-index`, `conversation-index`
   - Atributos: `message_id`, `conversation_id`, `sentiment`, `confidence`, `scores`

**Billing Mode:**
- `PAY_PER_REQUEST` (on-demand)

### 6.4. Pinecone

**Configura√ß√£o:**
- √çndice √∫nico: `genai-documents`
- Namespaces separados: `contracts`, `faqs`
- Embedding model: `text-embedding-ada-002` (OpenAI)

**Opera√ß√µes:**
- Inser√ß√£o em batch (100 vetores por vez)
- Busca por similaridade cosseno
- Metadados armazenam texto original e fonte

### 6.5. Dashboard (Opcional)

**Arquivo:** `dashboard/app.py`

**Funcionalidades:**
- Visualiza√ß√£o de conversas em tempo real
- An√°lise de sentimento por conversa
- WebSocket para atualiza√ß√µes live
- Estat√≠sticas gerais

**Tecnologias:**
- Flask-SocketIO para WebSocket
- Frontend: HTML/JS (templates/dashboard.html)

### 6.6. Demos ‚Äî site de demonstra√ß√£o

Site para **demonstrar os assistentes de IA** via chat na web com **suporte a upload de PDFs** para criar bases de conhecimento personalizadas.

- **Backend:** `backend/` ‚Äî API em `/api/demos` (listar assistentes, criar conversa, enviar mensagem, upload de PDF). Blueprint Flask registrado em `app/main.py`.
- **Frontend:** `frontend/` ‚Äî SPA React + Vite. Build: `cd frontend && npm install && npm run build`. Sa√≠da em `frontend/dist`.
- **Acesso:** Com a aplica√ß√£o Flask rodando e `frontend/dist` presente, o site √© servido em **`/demos`** (ex.: `http://localhost:5004/demos/`). A raiz `/` exibe um link para as demos.

**Endpoints da API de demos:**
- `GET /api/demos/assistants` ‚Äî lista assistentes dispon√≠veis
- `POST /api/demos/upload-pdf` ‚Äî faz upload de PDF e cria vector store (multipart/form-data: `file`, `agent_id`)
- `POST /api/demos/conversations` ‚Äî cria conversa (body opcional: `{ "agent_id": "juridico", "vector_store_id": "vs_xxx" }`)
- `POST /api/demos/conversations/<id>/messages` ‚Äî envia mensagem (body: `{ "content": "..." }`)
- `DELETE /api/demos/conversations/<id>` ‚Äî deleta conversa e limpa recursos (assistente customizado e vector store)

**Funcionalidades:**
- **Sele√ß√£o de Assistente:** Escolha entre os assistentes dispon√≠veis no registry (jur√≠dico, investimento, etc.)
- **Upload de PDF:** Fa√ßa upload de um PDF para criar uma base de conhecimento espec√≠fica para a conversa
- **Vector Store Din√¢mico:** Cada PDF √© processado e indexado em um vector store exclusivo usando a API de File Search da OpenAI
- **Assistente Customizado:** Quando um PDF √© enviado, um assistente espec√≠fico √© criado com acesso ao vector store
- **Limpeza Autom√°tica:** Recursos s√£o limpos ao trocar de assistente ou encerrar a conversa

Ver `docs/ARCHITECTURE.md` e as skills **backend-developer** e **frontend-developer** para detalhes.

---

## ‚öôÔ∏è Configura√ß√£o

### 7.1. Vari√°veis de Ambiente

**Arquivo:** `.env` (n√£o commitado) ou vari√°veis no Render

```bash
# OpenAI
OPENAI_API_KEY=sk-...
LLM_MODEL=gpt-4o
EMBEDDING_MODEL=text-embedding-ada-002

# Pinecone (base de conhecimento)
PINECONE_API_KEY=...
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=genai-documents

```

### 7.2. Depend√™ncias

**requirements.txt:**

Principais bibliotecas:
- `flask`: Framework web
- `openai`: Cliente OpenAI API
- `pinecone-client`: Cliente Pinecone
- `langchain`: Processamento de documentos
- `langchain-openai`: Integra√ß√£o OpenAI
- `pandas`: An√°lise de dados
- `openpyxl`: Leitura de Excel
- `pypdf`: Extra√ß√£o de texto PDF
- `vaderSentiment`: An√°lise de sentimento
- `textblob`: An√°lise de sentimento
- `gunicorn`: Servidor WSGI

### 7.3. Setup Inicial

1. **Clonar reposit√≥rio**
2. **Criar ambiente virtual:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   ```

3. **Instalar depend√™ncias:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configurar vari√°veis de ambiente:**
   - Copiar `.env.example` para `.env`
   - Preencher com credenciais (OpenAI, Pinecone). O projeto n√£o usa AWS nem Zatten.

5. **Executar aplica√ß√£o:**
   - A base de conhecimento vem dos arquivos que os clientes fazem upload na aplica√ß√£o (demos) e do Pinecone.
   - Threads e conversas ficam em mem√≥ria.

6. **Deploy no Render:**
   - Conectar reposit√≥rio Git
   - Configurar vari√°veis de ambiente
   - Deploy autom√°tico

---

## üìä Resumo T√©cnico

### Stack Completo

| Componente | Tecnologia |
|------------|------------|
| **LLM** | OpenAI GPT-4o (Assistant API) |
| **Vector DB** | Pinecone |
| **Cloud Storage** | AWS S3 |
| **NoSQL DB** | AWS DynamoDB |
| **Web Framework** | Flask (Python) |
| **Processamento** | asyncio, ThreadPoolExecutor |
| **Deploy** | Render |
| **An√°lise Sentimento** | VADER + TextBlob |
| **Data Analysis** | pandas + openpyxl |

### Arquitetura de Dados

- **Ingest√£o**: S3 ‚Üí PDF Processing ‚Üí Chunking ‚Üí Embeddings ‚Üí Pinecone
- **Busca**: Query ‚Üí Embedding ‚Üí Pinecone Search ‚Üí RAG
- **Contexto**: Phone ‚Üí DynamoDB ‚Üí Thread ID ‚Üí OpenAI Thread
- **An√°lise**: Message ‚Üí Sentiment Analysis ‚Üí DynamoDB ‚Üí Dashboard

### Escalabilidade

- **Queue-based processing**: Suporta picos de tr√°fego (quando aplic√°vel)
- **Cache**: Evita reprocessamento quando aplic√°vel
- **On-demand DynamoDB**: Escala automaticamente
- **Pinecone**: Otimizado para busca vetorial em escala

---

## üéØ Conclus√£o

Este sistema representa uma **solu√ß√£o completa de IA conversacional** para suporte automatizado, combinando:

‚úÖ **M√∫ltiplos agentes especializados** (contratos, FAQs, an√°lise de dados)  
‚úÖ **Busca vetorial avan√ßada** com Pinecone  
‚úÖ **An√°lise de sentimento** em tempo real  
‚úÖ **Persist√™ncia de contexto** via DynamoDB  
‚úÖ **Processamento ass√≠ncrono** para alta performance  
‚úÖ **Dashboard de monitoramento**  
‚úÖ **Arquitetura escal√°vel** na nuvem  

A arquitetura modular permite f√°cil extens√£o e manuten√ß√£o.
